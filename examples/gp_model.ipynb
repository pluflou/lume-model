{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bf3265d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from botorch.models import SingleTaskGP\n",
    "from botorch.fit import fit_gpytorch_model\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "from lume_model.variables import ScalarVariable, DistributionVariable\n",
    "from lume_model.models.gp_model import GPModel\n",
    "from gpytorch.kernels import RBFKernel\n",
    "from gpytorch.kernels import ScaleKernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95b1b10-5acd-4e26-8b74-2d243e0ce0be",
   "metadata": {},
   "source": [
    "# Multi-output example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53eab389-be6f-48a9-9521-c01a0c17a0ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/lume-latest-310/lib/python3.10/site-packages/botorch/models/utils/assorted.py:202: InputDataWarning: Input data is not standardized (mean = tensor([0.3013, 0.0843, 0.2563], dtype=torch.float64), std = tensor([0.7718, 0.7580, 0.7250], dtype=torch.float64)). Please consider scaling the input to zero mean and unit variance.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posterior Mean for each output:\n",
      "tensor([[ 0.1191,  1.0676,  0.8695],\n",
      "        [ 0.6962,  0.7921,  0.6797],\n",
      "        [ 1.0393,  0.2077,  0.3564],\n",
      "        [ 0.9186, -0.4773,  0.0466],\n",
      "        [ 0.3888, -0.9233, -0.1288],\n",
      "        [-0.2651, -0.8889, -0.1557],\n",
      "        [-0.7515, -0.4197, -0.0993],\n",
      "        [-0.9433,  0.1902, -0.0232],\n",
      "        [-0.8866,  0.6319,  0.0497],\n",
      "        [-0.7060,  0.7829,  0.1197]], dtype=torch.float64,\n",
      "       grad_fn=<CloneBackward0>)\n",
      "\n",
      "Posterior Variance for each output:\n",
      "tensor([[8.9528e-03, 6.5541e-03, 1.9921e-01],\n",
      "        [1.6997e-04, 1.0506e-04, 1.0898e-01],\n",
      "        [5.7277e-04, 3.9206e-04, 1.0253e-01],\n",
      "        [3.9346e-04, 2.5698e-04, 1.2137e-01],\n",
      "        [5.1715e-04, 3.8939e-04, 1.3695e-01],\n",
      "        [1.4667e-03, 1.1957e-03, 1.5283e-01],\n",
      "        [5.0446e-03, 4.6348e-03, 1.6268e-01],\n",
      "        [5.1627e-04, 3.7501e-04, 1.9050e-01],\n",
      "        [5.2062e-02, 5.0726e-02, 2.8656e-01],\n",
      "        [2.2894e-01, 2.2627e-01, 4.3334e-01]], dtype=torch.float64,\n",
      "       grad_fn=<CloneBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0);\n",
    "\n",
    "# Create training data, 1 input, 3 outputs\n",
    "train_x = torch.rand(5, 1)  \n",
    "train_y = torch.stack((\n",
    "    torch.sin(train_x * (2 * torch.pi)) + 0.1 * torch.randn(1),  \n",
    "    torch.cos(train_x * (2 * torch.pi)) + 0.1 * torch.randn(1),  \n",
    "    torch.sin(2 * train_x * (2 * torch.pi)) + 0.1 * torch.randn(1)  \n",
    "), dim=-1).squeeze(1) \n",
    "\n",
    "\n",
    "# Initialize the GP model\n",
    "rbf_kernel = ScaleKernel(RBFKernel())\n",
    "\n",
    "model = SingleTaskGP(\n",
    "    train_x.to(dtype=torch.double), \n",
    "    train_y.to(dtype=torch.double),\n",
    "    covar_module=rbf_kernel\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "mll = ExactMarginalLogLikelihood(model.likelihood, model)\n",
    "fit_gpytorch_model(mll)\n",
    "\n",
    "# Derive posterior mean and variance\n",
    "model.eval()\n",
    "test_x = torch.linspace(0, 1, 10).reshape(-1, 1).to(dtype=torch.double)\n",
    "posterior = model.posterior(test_x)\n",
    "\n",
    "# Derive the posterior mean and variance for each output\n",
    "mean = posterior.mean\n",
    "variance = posterior.variance\n",
    "print(\"Posterior Mean for each output:\")\n",
    "print(mean)\n",
    "print(\"\\nPosterior Variance for each output:\")\n",
    "print(variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b316363-a154-4ba8-b96b-30a22e400a35",
   "metadata": {},
   "source": [
    "## LUME-Model import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "746f7554-d317-400c-9e9b-47cb38422e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input variables\n",
    "input_variables = [ScalarVariable(name=\"x\")]\n",
    "\n",
    "# Define output variables\n",
    "# Currently the \"distribution_type\" field doesn't do anything\n",
    "output_variables = [\n",
    "    DistributionVariable(name=\"output1\", distribution_type=\"MultiVariateNormal\"),\n",
    "    DistributionVariable(name=\"output2\", distribution_type=\"MultiVariateNormal\"),\n",
    "    DistributionVariable(name=\"output3\", distribution_type=\"MultiVariateNormal\")\n",
    "]\n",
    "\n",
    "# Create lume_model instance\n",
    "gp_lume_model = GPModel(model=model, input_variables=input_variables, output_variables=output_variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ebbfdf-6bc4-4eae-a225-cce92a0e80e7",
   "metadata": {},
   "source": [
    "### Evaluate model and run methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b23c0a4-bf07-4351-b6e7-0762346f6e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dict = {\"x\": test_x.squeeze(1).to(dtype=torch.double)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "567cc4fb-aa01-40d6-be27-4839eaf23ebb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': tensor([0.0000, 0.1111, 0.2222, 0.3333, 0.4444, 0.5556, 0.6667, 0.7778, 0.8889,\n",
       "         1.0000], dtype=torch.float64)}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a20e922c-22e3-445d-913d-b735ab7c62fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate function returns a dictionary mapping each output to a torch.distributions.Distribution\n",
    "output_dict = gp_lume_model.evaluate(input_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2028eda3-7e67-474e-9d71-9d286d3f0749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output1': MultivariateNormal(loc: torch.Size([10]), covariance_matrix: torch.Size([10, 10])),\n",
       " 'output2': MultivariateNormal(loc: torch.Size([10]), covariance_matrix: torch.Size([10, 10])),\n",
       " 'output3': MultivariateNormal(loc: torch.Size([10]), covariance_matrix: torch.Size([10, 10]))}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "410be85e-8342-4441-b739-3f3f342d1810",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prob = output_dict[\"output1\"].sample(torch.Size([2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77268fda-342b-4319-bc50-2504e9b65817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posterior mean: tensor([ 0.1191,  0.6962,  1.0393,  0.9186,  0.3888, -0.2651, -0.7515, -0.9433,\n",
      "        -0.8866, -0.7060], dtype=torch.float64, grad_fn=<ExpandBackward0>)\n",
      "Posterior Variance  tensor([8.9528e-03, 1.6997e-04, 5.7277e-04, 3.9346e-04, 5.1715e-04, 1.4667e-03,\n",
      "        5.0446e-03, 5.1627e-04, 5.2062e-02, 2.2894e-01], dtype=torch.float64,\n",
      "       grad_fn=<ExpandBackward0>)\n",
      "Log Likelihood tensor([23.0400, 23.1697], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "Rsample  tensor([[ 0.0907,  0.7043,  1.0711,  0.9269,  0.3688, -0.2822, -0.7675, -0.9718,\n",
      "         -0.9131, -0.7421],\n",
      "        [ 0.0608,  0.6952,  1.0342,  0.9255,  0.4047, -0.3430, -0.8944, -0.9312,\n",
      "         -0.6536, -0.5014],\n",
      "        [-0.0622,  0.6853,  1.0661,  0.9004,  0.3716, -0.2221, -0.6966, -0.9473,\n",
      "         -0.8827, -0.5358]], dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(\"Posterior mean:\", output_dict[\"output1\"].mean)\n",
    "print(\"Posterior Variance \", output_dict[\"output1\"].variance)\n",
    "print(\"Log Likelihood\", output_dict[\"output1\"].log_prob(test_prob))\n",
    "print(\"Rsample \", output_dict[\"output1\"].rsample(torch.Size([3])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5326ad-fd2a-4432-bae2-19c078c86d8c",
   "metadata": {},
   "source": [
    "### Outputs with original model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9883480-f8fd-4899-8417-a8e041da0204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posterior mean: tensor([ 0.1191,  0.6962,  1.0393,  0.9186,  0.3888, -0.2651, -0.7515, -0.9433,\n",
      "        -0.8866, -0.7060], dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "Posterior Variance  tensor([8.9528e-03, 1.6997e-04, 5.7277e-04, 3.9346e-04, 5.1715e-04, 1.4667e-03,\n",
      "        5.0446e-03, 5.1627e-04, 5.2062e-02, 2.2894e-01], dtype=torch.float64,\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(\"Posterior mean:\", posterior.mean[:,0])\n",
    "print(\"Posterior Variance \", posterior.variance[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e909f9-5d88-49a3-a8e6-777774a57b4b",
   "metadata": {},
   "source": [
    "# A 3D Rosenbrock example for GPModel class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13423e73-2e5b-419d-be48-c979472a281c",
   "metadata": {},
   "source": [
    "## Create and train a GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e1caf84-00be-414d-a9b6-9d4f846290e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the 3D Rosenbrock function\n",
    "def rosenbrock(X):\n",
    "    x1, x2, x3 = X[..., 0], X[..., 1], X[..., 2]\n",
    "    return (1 - x1)**2 + 100 * (x2 - x1**2)**2 + (1 - x2)**2 + 100 * (x3 - x2**2)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9ed72c5-3256-4b17-9713-54d2eb46dac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/lume-latest-310/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/opt/miniconda3/envs/lume-latest-310/lib/python3.10/site-packages/botorch/models/utils/assorted.py:202: InputDataWarning: Input data is not standardized (mean = tensor([667.0384], dtype=torch.float64), std = tensor([638.0577], dtype=torch.float64)). Please consider scaling the input to zero mean and unit variance.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posterior mean:  tensor([[709.2621],\n",
      "        [743.0249],\n",
      "        [816.8719],\n",
      "        [877.1305],\n",
      "        [599.5735],\n",
      "        [927.9536],\n",
      "        [755.8055],\n",
      "        [733.1906],\n",
      "        [670.7312],\n",
      "        [804.1502]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Posterior variance:  tensor([[1061.7684],\n",
      "        [1292.8560],\n",
      "        [1239.0013],\n",
      "        [1197.7443],\n",
      "        [1042.3683],\n",
      "        [1216.5796],\n",
      "        [1220.7746],\n",
      "        [1243.2245],\n",
      "        [1091.1481],\n",
      "        [1139.7435]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Generate training data\n",
    "train_x = torch.rand(20, 3) * 4 - 2  # 20 points in 3D space, scaled to [-2, 2]\n",
    "train_y = rosenbrock(train_x).unsqueeze(-1)  # Compute the Rosenbrock function values\n",
    "\n",
    "# Define the GP model\n",
    "gp_model = SingleTaskGP(train_x.to(dtype=torch.double), train_y.to(dtype=torch.double))\n",
    "\n",
    "# Fit the model\n",
    "mll = ExactMarginalLogLikelihood(gp_model.likelihood, gp_model)\n",
    "fit_gpytorch_model(mll)\n",
    "\n",
    "# Evaluate the model on test data\n",
    "test_x = torch.rand(10, 3) * 4 - 2  # 10 new points in 3D space\n",
    "gp_model.eval()\n",
    "posterior = gp_model.posterior(test_x)\n",
    "\n",
    "# Get the mean and variance of the posterior\n",
    "mean = posterior.mean\n",
    "variance = posterior.variance\n",
    "\n",
    "print(\"Posterior mean: \", mean)\n",
    "print(\"Posterior variance: \", variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f42d852-dbef-4ec8-814a-fa3f94b8f24b",
   "metadata": {},
   "source": [
    "## LUME-Model import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d256cedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input variables\n",
    "input_variables = [ScalarVariable(name=\"x1\"), ScalarVariable(name=\"x2\"), ScalarVariable(name=\"x3\")]\n",
    "\n",
    "# Define output variables\n",
    "# Currently the \"distribution_type\" field doesn't do anything\n",
    "output_variables = [DistributionVariable(name=\"output1\", distribution_type=\"MultiVariateNormal\")]\n",
    "\n",
    "# Create lume_model instance\n",
    "gp_lume_model = GPModel(model=gp_model, input_variables=input_variables, output_variables=output_variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8144a2e-7221-4c4f-8b40-d07d21e67e31",
   "metadata": {},
   "source": [
    "#### Evaluate model and run methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d8e61307-8ff8-45ea-8ea1-d2a846e3beaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_x = torch.rand(3, 3) * 4 - 2  # 3 new points in 3D space\n",
    "input_dict = {\"x1\": input_x[:,0].to(dtype=torch.double),\n",
    "              \"x2\": input_x[:,1].to(dtype=torch.double),\n",
    "              \"x3\": input_x[:,2].to(dtype=torch.double)\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb69c88b-a94d-4c0b-bee8-2ae0b40a3577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate function returns a dictionary mapping each output to a torch.distributions.Distribution\n",
    "lume_dist = gp_lume_model.evaluate(input_dict)[\"output1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "424760a2-2626-4c60-a7db-9baaf1b60084",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_test = torch.rand(1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f9c4f8d8-da8e-44d2-b18c-53fb6f75897a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posterior mean: tensor([641.3173, 759.6992, 858.2711], dtype=torch.float64,\n",
      "       grad_fn=<ViewBackward0>)\n",
      "Posterior Variance  tensor([1157.0986, 1205.8884, 1203.6263], dtype=torch.float64,\n",
      "       grad_fn=<ExpandBackward0>)\n",
      "Log Likelihood tensor([-632.0540], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "Rsample  tensor([[649.7874, 771.1869, 917.4273],\n",
      "        [659.0826, 787.8484, 819.4870],\n",
      "        [664.5120, 787.8166, 925.1078]], dtype=torch.float64,\n",
      "       grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(\"Posterior mean:\", lume_dist.mean)\n",
    "print(\"Posterior Variance \", lume_dist.variance)\n",
    "print(\"Log Likelihood\", lume_dist.log_prob(rand_test))\n",
    "print(\"Rsample \", lume_dist.rsample(torch.Size([3])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b8ab31-78e7-4d2c-816a-b8c8373f427a",
   "metadata": {},
   "source": [
    "### Outputs with original model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fd60e0f6-9e0e-47e0-8fa5-82b97778375b",
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior = gp_model.posterior(input_x)\n",
    "botorch_dist = posterior.distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1d0254a6-6059-420c-9184-ca8bc4b464d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posterior mean: tensor([641.3173, 759.6992, 858.2711], dtype=torch.float64,\n",
      "       grad_fn=<ViewBackward0>)\n",
      "Posterior Variance  tensor([1157.0986, 1205.8884, 1203.6263], dtype=torch.float64,\n",
      "       grad_fn=<ExpandBackward0>)\n",
      "Log Likelihood tensor([-632.0540], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "Rsample  tensor([[634.2593, 713.9684, 836.3392],\n",
      "        [639.7731, 767.2576, 822.1241],\n",
      "        [610.8663, 755.6557, 825.8629]], dtype=torch.float64,\n",
      "       grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(\"Posterior mean:\", botorch_dist.mean)\n",
    "print(\"Posterior Variance \", botorch_dist.variance)\n",
    "print(\"Log Likelihood\", botorch_dist.log_prob(rand_test))\n",
    "print(\"Rsample \", botorch_dist.rsample(torch.Size([3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f18e906-fdcb-4431-8a12-2e9054bb259f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
